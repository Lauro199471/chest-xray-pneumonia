{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple CIFAR-10 image classifier using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.0.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tensorflow version: \",tf.__version__)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 73,418\n",
      "Trainable params: 73,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size = 3,activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters = 64, kernel_size = 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters = 64, kernel_size = 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a data pipeline\n",
    "To train this model, we need a data pipeline to feed it labeled training data. A data pipeline performs the following tasks:<br>\n",
    "<li><b>Loading</b>: Copying the dataset (e.g. images and labels) from storage into the program's memory.<br>\n",
    "<li><b>Preprocessing</b>: transforming the dataset. For example, in image classification, we might resize, whiten, shuffle, or batch images.<br>\n",
    "<li><b>Feeding</b>: shoveling examples from a dataset into a training loop.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (50000, 32, 32, 3)\n",
      "train_label shape:  (50000, 1)\n",
      "\n",
      "\n",
      "test_data shape:  (10000, 32, 32, 3)\n",
      "test_label shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_label), (test_data, test_label) = keras.datasets.cifar10.load_data()\n",
    "train_data, test_data = train_data / 255.0, test_data / 255.0\n",
    "\n",
    "print(\"train_data shape: \", np.shape(train_data))\n",
    "print(\"train_label shape: \", np.shape(train_label))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"test_data shape: \", np.shape(test_data))\n",
    "print(\"test_label shape: \", np.shape(test_label))\n",
    "\n",
    "# Get info for test data\n",
    "N_EXAMPLE,HEIGHT,WIDTH,NUM_CHANNELS = np.shape(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_data` represents 50,000 images with dimension 32 x 32 x 3 (width, height, and three RGB channels).<br>\n",
    "`train_label` represents labels for these 50,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Data\n",
    "def display_image(data,rows=3,cols=3):\n",
    "    n=1\n",
    "    fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "\n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            for image , label in data.take(n):\n",
    "                ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "                ax.grid('off')\n",
    "                ax.axis('off')\n",
    "                plt.imshow(image)\n",
    "        \n",
    "                pred_label = 0.0 #cifar10_classes[y_pred_test_classes[random_index]]\n",
    "                pred_proba = 0.0 #y_pred_test_max_probas[random_index]\n",
    "                true_label = cifar10_classes[label.numpy()[0]]\n",
    "                ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "                pred_label, pred_proba, true_label))\n",
    "            n = n + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In theory, we could simply feed these raw data into a training loop and call this a data pipeline. However, to achieve higher model accuracy, we'll want to preprocess the data (i.e. perform certain transformations on it before usage). To do so, we leverage <i>Tensorflow's Dataset class.</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tf.data.Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow Dataset class serves two main purposes:<br>\n",
    "<li>It acts as a container that holds training data.\n",
    "<li>It can be used to perform alterations on elements of the training data.\n",
    "    \n",
    "We instantiate a `tensorflow.data.Dataset` object representing the CIFAR-10 dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Instantiate the Dataset class.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "test_dataset  = tf.data.Dataset.from_tensor_slices((test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(train_dataset,rows=1,cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the CIFAR-10 training examples stored in `train_dataset` will be accessed via the `take()` iterator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "Augmentation is often used to <b>\"inflate\"</b> training datasets, which can improve generalization performance.<br>\n",
    "\n",
    "Let's augment the CIFAR-10 dataset by performing the following steps on every image:<br>\n",
    "1. Pad the image with a black, four-pixel border.\n",
    "2. Randomly crop a 32 x 32 region from the padded image.\n",
    "3. Flip a coin to determine if the image should be horizontally flipped.<br><br>\n",
    "\n",
    "We achieve this by first defining a function that, given an image, performs the Steps 1-3 above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(x, y):\n",
    "    x = tf.image.resize_with_crop_or_pad(\n",
    "        x, HEIGHT + 8, WIDTH + 8)\n",
    "    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the method `map`; this call returns a new `Dataset` object that contains the result of passing each image in CIFAR-10 into `augmentation`. This new object will emit transformed images in the original order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = train_dataset.map(augmentation)\n",
    "display_image(train_datasets,rows=4,cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling\n",
    "We randomly shuffle the dataset. TensorFlow Dataset has a `shuffle` method, which can be chained to our augmentation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = (train_dataset\n",
    "                 .map(augmentation)\n",
    "                 .shuffle(buffer_size=N_EXAMPLE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(train_datasets,rows=2,cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For perfect shuffling, the `buffer_size` should be greater than or equal to the size of the dataset (in this case: 50,000); for large datasets, this isn't possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "It's common practice to normalize data. Here, define a function that linearly scales each image to have zero mean and unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, y):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we chain it with our augmentation and shuffling operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = (train_dataset\n",
    "                 .map(augmentation)\n",
    "                 .shuffle(buffer_size=N_EXAMPLE)\n",
    "                 .map(normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "Finally, we `batch` the dataset. We set `drop_remainder` to `True` to remove enough training examples so that the training set's size is divisible by `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_dataset.map(augmentation)\n",
    "                 .map(normalize)\n",
    "                 .shuffle(N_EXAMPLE)\n",
    "                 .batch(128, drop_remainder=True))\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a complete data pipeline. Now we can start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "A Keras model needs to be compiled before training. Compilation essentially defines three things: the `loss function`, the `optimizer` and the `metrics` for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          optimizer='adam',#keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we use `sparse_categorical_crossentropy` and `sparse_categorical_accuracy` here because each label is represented by a single integer (index of the class). One should use `categorical_crossentropy` and `categorical_accuracy` if a one-hot vector represents each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 7s 140us/sample - loss: 1.0618 - accuracy: 0.6285 - val_loss: 1.0207 - val_accuracy: 0.6466\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 7s 142us/sample - loss: 0.9636 - accuracy: 0.6643 - val_loss: 0.9906 - val_accuracy: 0.6560\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 7s 140us/sample - loss: 0.8860 - accuracy: 0.6911 - val_loss: 0.9209 - val_accuracy: 0.6822\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.8314 - accuracy: 0.7120 - val_loss: 0.9420 - val_accuracy: 0.6798\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.7848 - accuracy: 0.7269 - val_loss: 0.8807 - val_accuracy: 0.6981\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.7443 - accuracy: 0.7398 - val_loss: 0.8710 - val_accuracy: 0.7036\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 7s 140us/sample - loss: 0.7092 - accuracy: 0.7532 - val_loss: 0.8565 - val_accuracy: 0.7134\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 7s 149us/sample - loss: 0.6761 - accuracy: 0.7628 - val_loss: 0.8802 - val_accuracy: 0.7059\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 7s 142us/sample - loss: 0.6489 - accuracy: 0.7719 - val_loss: 0.8861 - val_accuracy: 0.7066\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 7s 146us/sample - loss: 0.6240 - accuracy: 0.7821 - val_loss: 0.8610 - val_accuracy: 0.7169\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 7s 143us/sample - loss: 0.5963 - accuracy: 0.7919 - val_loss: 0.8992 - val_accuracy: 0.7076\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 7s 147us/sample - loss: 0.5756 - accuracy: 0.7959 - val_loss: 0.9689 - val_accuracy: 0.6863\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 7s 143us/sample - loss: 0.5562 - accuracy: 0.8037 - val_loss: 0.8774 - val_accuracy: 0.7175\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.5364 - accuracy: 0.8099 - val_loss: 0.9644 - val_accuracy: 0.7070\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.5196 - accuracy: 0.8168 - val_loss: 0.9066 - val_accuracy: 0.7225\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.5054 - accuracy: 0.8203 - val_loss: 1.0025 - val_accuracy: 0.7043\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.4872 - accuracy: 0.8283 - val_loss: 0.9613 - val_accuracy: 0.7020\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.4716 - accuracy: 0.8335 - val_loss: 0.9619 - val_accuracy: 0.7129\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.4576 - accuracy: 0.8367 - val_loss: 0.9930 - val_accuracy: 0.7077\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.4426 - accuracy: 0.8412 - val_loss: 1.0003 - val_accuracy: 0.7049\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.4320 - accuracy: 0.8451 - val_loss: 1.0129 - val_accuracy: 0.7106\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.4138 - accuracy: 0.8528 - val_loss: 1.0343 - val_accuracy: 0.7099\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 7s 139us/sample - loss: 0.4047 - accuracy: 0.8556 - val_loss: 1.0347 - val_accuracy: 0.7082\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.3912 - accuracy: 0.8578 - val_loss: 1.0734 - val_accuracy: 0.7066\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.3813 - accuracy: 0.8640 - val_loss: 1.1032 - val_accuracy: 0.7003\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.3724 - accuracy: 0.8667 - val_loss: 1.1277 - val_accuracy: 0.7021\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 7s 139us/sample - loss: 0.3578 - accuracy: 0.8724 - val_loss: 1.1457 - val_accuracy: 0.7067\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.3483 - accuracy: 0.8757 - val_loss: 1.1543 - val_accuracy: 0.7015\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.3382 - accuracy: 0.8789 - val_loss: 1.1843 - val_accuracy: 0.7077\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 7s 138us/sample - loss: 0.3260 - accuracy: 0.8829 - val_loss: 1.2366 - val_accuracy: 0.7021\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.3166 - accuracy: 0.8855 - val_loss: 1.2492 - val_accuracy: 0.6989\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.3149 - accuracy: 0.8861 - val_loss: 1.2625 - val_accuracy: 0.7005\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2998 - accuracy: 0.8928 - val_loss: 1.3949 - val_accuracy: 0.6884\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2975 - accuracy: 0.8927 - val_loss: 1.3174 - val_accuracy: 0.6945\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 7s 138us/sample - loss: 0.2830 - accuracy: 0.8976 - val_loss: 1.3397 - val_accuracy: 0.6984\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 7s 142us/sample - loss: 0.2853 - accuracy: 0.8972 - val_loss: 1.3567 - val_accuracy: 0.6985\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 7s 138us/sample - loss: 0.2774 - accuracy: 0.8991 - val_loss: 1.3696 - val_accuracy: 0.7087\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2660 - accuracy: 0.9037 - val_loss: 1.4132 - val_accuracy: 0.6979\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2607 - accuracy: 0.9043 - val_loss: 1.5070 - val_accuracy: 0.6953\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2556 - accuracy: 0.9086 - val_loss: 1.5327 - val_accuracy: 0.6877\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2481 - accuracy: 0.9096 - val_loss: 1.4969 - val_accuracy: 0.7024\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2511 - accuracy: 0.9093 - val_loss: 1.5261 - val_accuracy: 0.7007\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2379 - accuracy: 0.9135 - val_loss: 1.5683 - val_accuracy: 0.6954\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2383 - accuracy: 0.9147 - val_loss: 1.7128 - val_accuracy: 0.6790\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2303 - accuracy: 0.9156 - val_loss: 1.6855 - val_accuracy: 0.6912\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2199 - accuracy: 0.9203 - val_loss: 1.6710 - val_accuracy: 0.6860\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2209 - accuracy: 0.9205 - val_loss: 1.6888 - val_accuracy: 0.6904\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.2233 - accuracy: 0.9199 - val_loss: 1.6658 - val_accuracy: 0.6968\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2141 - accuracy: 0.9204 - val_loss: 1.7704 - val_accuracy: 0.6860\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2095 - accuracy: 0.9240 - val_loss: 1.7351 - val_accuracy: 0.6935\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.2066 - accuracy: 0.9254 - val_loss: 1.7635 - val_accuracy: 0.6960\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.2002 - accuracy: 0.9288 - val_loss: 1.8402 - val_accuracy: 0.6950\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.2001 - accuracy: 0.9271 - val_loss: 1.7813 - val_accuracy: 0.6970\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.1971 - accuracy: 0.9290 - val_loss: 1.8550 - val_accuracy: 0.6860\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.1915 - accuracy: 0.9307 - val_loss: 1.8196 - val_accuracy: 0.7004\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 7s 136us/sample - loss: 0.1886 - accuracy: 0.9313 - val_loss: 1.8754 - val_accuracy: 0.6848\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 7s 135us/sample - loss: 0.1920 - accuracy: 0.9308 - val_loss: 1.8604 - val_accuracy: 0.6911\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.1820 - accuracy: 0.9345 - val_loss: 1.9354 - val_accuracy: 0.6939\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 7s 137us/sample - loss: 0.1914 - accuracy: 0.9302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-32ede10ac8bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m          )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m                       total_epochs=1)\n\u001b[0m\u001b[0;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m    372\u001b[0m                                  prefix='val_')\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(np.shape(train_data))\n",
    "print(np.shape(train_label))\n",
    "\n",
    "model.fit(train_data,\n",
    "          train_label,\n",
    "          epochs=200,\n",
    "          validation_data = (test_data,test_label)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
